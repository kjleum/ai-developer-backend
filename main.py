from fastapi import FastAPI, HTTPException, BackgroundTasks, UploadFile, File, WebSocket
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from contextlib import asynccontextmanager
import os
from dotenv import load_dotenv
import random
import json
import asyncio
from typing import Optional, List

load_dotenv()

from models.schemas import *
from core.ai_manager import AIManager
from core.project_builder import ProjectBuilder
from core.deploy_engine import DeployEngine
from core.database import Database
from core.media_processor import MediaProcessor
from core.agent_system import AgentSystem
from core.rag_engine import RAGEngine
from core.nlp_interface import NLPInterface

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
ai_manager = AIManager()
project_builder = ProjectBuilder()
deploy_engine = DeployEngine()
db = Database()
media_processor = MediaProcessor()
agent_system = AgentSystem(ai_manager, None, db)
rag_engine = RAGEngine(ai_manager)
nlp_interface = NLPInterface(ai_manager, db)

@asynccontextmanager
async def lifespan(app: FastAPI):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ"""
    print("üöÄ AI Developer Platform v4.0 –∑–∞–ø—É—â–µ–Ω")
    print("üì¶ –ú–æ–¥—É–ª–∏: AI, Media, Agents, RAG, NLP")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–µ—Ä–≤–∏—Å—ã
    services = await media_processor.check_services()
    print(f"   –ú–µ–¥–∏–∞-—Å–µ—Ä–≤–∏—Å—ã: {sum(services.values())}/{len(services)} –¥–æ—Å—Ç—É–ø–Ω–æ")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG
    await rag_engine.initialize()

    yield
    print("üëã –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã")

app = FastAPI(
    title="AI Developer Platform v4.0",
    description="""
    –ü–æ–ª–Ω–æ—Ü–µ–Ω–Ω–∞—è AI-–ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏:
    - ü§ñ LLM (9+ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ + Ollama)
    - üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (SD, Kandinsky)
    - üé¨ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ (Wan, Kandinsky Video)
    - üé§ TTS/STT (Coqui, Whisper)
    - üß† AI –ê–≥–µ–Ω—Ç—ã (5 —Ç–∏–ø–æ–≤ + Flowise/Activepieces)
    - üìö RAG (Chroma/Qdrant/pgvector)
    - üí¨ NLP –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∫ –ë–î
    """,
    version="4.0.0",
    lifespan=lifespan
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============ AI ENDPOINTS ============

@app.get("/ai/providers")
async def get_ai_providers():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤"""
    providers = ai_manager.get_available_providers()
    best = ai_manager.get_best_available_provider()
    return {
        "providers": providers,
        "recommended": best,
        "total_available": len([p for p in providers if p["available"]]),
        "total_free": len([p for p in providers if p["cost"] == "–ë–µ—Å–ø–ª–∞—Ç–Ω–æ"]),
        "capabilities": ["chat", "vision", "code", "embeddings", "function_calling"]
    }

@app.post("/ai/generate")
async def ai_generate(request: GenerateRequest):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ AI"""
    try:
        response = await ai_manager.generate(
            prompt=request.prompt,
            provider=request.provider,
            model=request.model,
            temperature=request.temperature,
            max_tokens=request.max_tokens,
            json_mode=request.json_mode
        )
        return {"success": True, "response": response, "provider": request.provider or "auto"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/embeddings")
async def ai_embeddings(request: EmbeddingsRequest):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è RAG"""
    try:
        embeddings = await ai_manager.generate_embeddings(
            texts=request.texts,
            provider=request.provider
        )
        return {"success": True, "embeddings": embeddings, "count": len(embeddings)}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.websocket("/ai/stream")
async def ai_stream(websocket: WebSocket):
    """–°—Ç—Ä–∏–º–∏–Ω–≥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ WebSocket"""
    await websocket.accept()
    try:
        while True:
            data = await websocket.receive_json()
            prompt = data.get("prompt")
            provider = data.get("provider")

            # –°—Ç—Ä–∏–º–∏–Ω–≥ —á–µ—Ä–µ–∑ Ollama –∏–ª–∏ –¥—Ä—É–≥–æ–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä
            if provider == "ollama":
                async for chunk in ai_manager._call_ollama(prompt, stream=True):
                    await websocket.send_text(chunk)
            else:
                response = await ai_manager.generate(prompt, provider)
                await websocket.send_text(response)

            await websocket.send_text("[DONE]")
    except Exception as e:
        await websocket.send_text(f"[ERROR] {str(e)}")
    finally:
        await websocket.close()

# ============ MEDIA ENDPOINTS ============

@app.get("/media/services")
async def get_media_services():
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–µ–¥–∏–∞-—Å–µ—Ä–≤–∏—Å–æ–≤"""
    services = await media_processor.check_services()
    return {
        "services": services,
        "available": sum(services.values()),
        "total": len(services)
    }

@app.post("/media/image/generate")
async def generate_image(request: ImageGenerationRequest):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    try:
        result = await media_processor.generate_image(
            prompt=request.prompt,
            negative_prompt=request.negative_prompt,
            width=request.width,
            height=request.height,
            model=request.model,
            steps=request.steps,
            cfg_scale=request.cfg_scale
        )
        return {"success": True, **result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/media/image/upscale")
async def upscale_image(request: UpscaleRequest):
    """–£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è"""
    try:
        result = await media_processor.upscale(request.image, request.scale)
        return {"success": True, **result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/media/video/generate")
async def generate_video(request: VideoGenerationRequest):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ"""
    try:
        result = await media_processor.generate_video(
            prompt=request.prompt,
            image=request.image,
            duration=request.duration,
            model=request.model
        )
        return {"success": True, **result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/media/audio/tts")
async def text_to_speech(request: TTSRequest):
    """–¢–µ–∫—Å—Ç –≤ —Ä–µ—á—å"""
    try:
        result = await media_processor.text_to_speech(
            text=request.text,
            voice=request.voice,
            language=request.language,
            speed=request.speed
        )
        return {"success": True, **result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/media/audio/stt")
async def speech_to_text(request: STTRequest):
    """–†–µ—á—å –≤ —Ç–µ–∫—Å—Ç"""
    try:
        result = await media_processor.speech_to_text(
            audio=request.audio,
            language=request.language,
            model=request.model
        )
        return {"success": True, **result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/media/audio/clone-voice")
async def clone_voice(request: VoiceCloneRequest):
    """–ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞"""
    try:
        result = await media_processor.clone_voice(
            audio_samples=request.samples,
            name=request.name
        )
        return {"success": True, **result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ============ AGENT ENDPOINTS ============

@app.get("/agents")
async def get_agents():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∞–≥–µ–Ω—Ç–æ–≤"""
    return {
        "agents": agent_system.get_agents(),
        "default_agents": ["developer", "analyst", "support", "manager", "creative"]
    }

@app.post("/agents/{agent_id}/run")
async def run_agent(agent_id: str, request: AgentRunRequest):
    """–ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–≥–µ–Ω—Ç–∞"""
    try:
        result = await agent_system.run_agent(
            agent_id=agent_id,
            user_input=request.input,
            context=request.context
        )
        return {"success": True, **result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/agents/create")
async def create_agent(request: CreateAgentRequest):
    """–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤–æ–≥–æ –∞–≥–µ–Ω—Ç–∞"""
    try:
        agent = await agent_system.create_agent(
            name=request.name,
            description=request.description,
            capabilities=request.capabilities,
            system_prompt=request.system_prompt,
            tools=request.tools,
            custom_params=request.custom_params
        )
        return {"success": True, "agent": {"id": agent.id, "name": agent.name}}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/agents/tasks")
async def get_agent_tasks(status: Optional[str] = None):
    """–ü–æ–ª—É—á–∏—Ç—å –∑–∞–¥–∞—á–∏ –∞–≥–µ–Ω—Ç–æ–≤"""
    return {"tasks": agent_system.get_tasks(status)}

# ============ RAG ENDPOINTS ============

@app.post("/rag/collections")
async def create_collection(request: CreateCollectionRequest):
    """–°–æ–∑–¥–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é –¥–ª—è RAG"""
    try:
        result = await rag_engine.create_collection(
            name=request.name,
            dimension=request.dimension,
            metadata=request.metadata
        )
        return {"success": True, **result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/rag/collections/{collection}/documents")
async def add_documents(collection: str, request: AddDocumentsRequest):
    """–î–æ–±–∞–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é"""
    try:
        from core.rag_engine import Document
        documents = [
            Document(
                id=doc.id or str(random.randint(10000, 99999)),
                content=doc.content,
                metadata=doc.metadata,
                embedding=doc.embedding
            )
            for doc in request.documents
        ]

        result = await rag_engine.add_documents(collection, documents)
        return {"success": True, **result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/rag/collections/{collection}/search")
async def search_documents(collection: str, request: SearchRequest):
    """–ü–æ–∏—Å–∫ –ø–æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏"""
    try:
        results = await rag_engine.search(
            collection=collection,
            query=request.query,
            top_k=request.top_k,
            filter_metadata=request.filter
        )
        return {"success": True, "results": results, "count": len(results)}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/rag/chat")
async def rag_chat(request: RAGChatRequest):
    """–ß–∞—Ç —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏"""
    try:
        result = await rag_engine.chat_with_documents(
            collection=request.collection,
            query=request.query,
            system_prompt=request.system_prompt,
            chat_history=request.history,
            top_k=request.top_k
        )
        return {"success": True, **result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ============ NLP INTERFACE ENDPOINTS ============

@app.post("/nlp/command")
async def nlp_command(request: NLPCommandRequest):
    """–í—ã–ø–æ–ª–Ω–∏—Ç—å –∫–æ–º–∞–Ω–¥—É –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–º —è–∑—ã–∫–µ"""
    try:
        # –ü–∞—Ä—Å–∏–º –∫–æ–º–∞–Ω–¥—É
        command = await nlp_interface.parse_command(request.command, request.context)

        # –í—ã–ø–æ–ª–Ω—è–µ–º –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω—ã
        if command.confidence > 0.7:
            result = await nlp_interface.execute_command(command, request.user_id)
            return {"success": True, "parsed": command.__dict__, "result": result}
        else:
            # –ò–Ω–∞—á–µ —á–∞—Ç-—Ä–µ–∂–∏–º
            chat_result = await nlp_interface.chat_with_data(request.command, request.user_id)
            return {"success": True, "mode": "chat", **chat_result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/nlp/chat")
async def nlp_chat(request: NLPChatRequest):
    """–°–≤–æ–±–æ–¥–Ω—ã–π —á–∞—Ç —Å –¥–∞–Ω–Ω—ã–º–∏"""
    try:
        result = await nlp_interface.chat_with_data(request.message, request.user_id)
        return {"success": True, **result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ============ PROJECT ENDPOINTS (–æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–µ) ============

TRENDING_TOPICS = [
    "Telegram –±–æ—Ç –¥–ª—è –ø—Ä–æ–¥–∞–∂", "CRM —Å–∏—Å—Ç–µ–º–∞", "–°–µ—Ä–≤–∏—Å –±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è",
    "API –¥–ª—è –¥–æ—Å—Ç–∞–≤–∫–∏", "AI —á–∞—Ç", "–§–∏–Ω–∞–Ω—Å–æ–≤—ã–π —Ç—Ä–µ–∫–µ—Ä",
    "–ú–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å", "–°–∏—Å—Ç–µ–º–∞ –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏", "–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö",
    "SaaS –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞", "ERP —Å–∏—Å—Ç–µ–º–∞", "–ü–∞—Ä—Å–µ—Ä —Ç–æ–≤–∞—Ä–æ–≤"
]

@app.get("/examples")
async def get_examples():
    """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–µ–∫—Ç–æ–≤"""
    try:
        selected_topics = random.sample(TRENDING_TOPICS, min(4, len(TRENDING_TOPICS)))
        examples = []

        for topic in selected_topics:
            prompt = f"""–°–æ–∑–¥–∞–π –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ "{topic}" –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞.
–û—Ç–≤–µ—Ç—å JSON: {{"title": "...", "description": "...", "type": "api/bot/saas/marketplace/crm/erp", "features": [], "stack": []}}"""

            try:
                response = await ai_manager.generate(prompt=prompt, temperature=0.8, max_tokens=500, json_mode=True)
                data = json.loads(ai_manager.clean_json_response(response))

                examples.append({
                    "id": f"example_{topic.replace(' ', '_').lower()}",
                    "title": data.get("title", topic),
                    "description": data.get("description", f"–ü—Ä–æ–µ–∫—Ç: {topic}"),
                    "icon": get_icon_for_type(data.get("type", "api")),
                    "category": data.get("type", "api"),
                    "config_preview": {
                        "type": data.get("type", "api"),
                        "name": topic,
                        "features": [{"name": f, "description": f, "priority": "must"} for f in data.get("features", [])[:3]],
                        "database": "postgresql"
                    }
                })
            except:
                examples.append(create_fallback_example(topic))

        return {"examples": examples, "total_available": len(TRENDINGING_TOPICS)}
    except Exception as e:
        return {"examples": [create_fallback_example(t) for t in random.sample(TRENDING_TOPICS, 4)], "error": str(e)}

def get_icon_for_type(project_type: str) -> str:
    icons = {
        "api": "üîå", "bot": "ü§ñ", "frontend": "üé®", "saas": "‚òÅÔ∏è",
        "marketplace": "üõí", "crm": "üë•", "erp": "üìä", "scraper": "üîç",
        "fullstack": "‚ö°", "cli": "‚å®Ô∏è"
    }
    return icons.get(project_type, "üì¶")

def create_fallback_example(topic: str) -> dict:
    return {
        "id": f"fallback_{topic.replace(' ', '_').lower()}",
        "title": f"üì¶ {topic}",
        "description": f"–ü–æ–ª–Ω–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Å–µ—Ä–≤–∏—Å –¥–ª—è {topic.lower()}",
        "icon": "üöÄ",
        "category": "api",
        "config_preview": {"type": "api", "name": topic, "features": []}
    }

@app.post("/projects")
async def create_project(request: CreateProjectRequest, background_tasks: BackgroundTasks):
    """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞"""
    try:
        project_id = await db.create_project(request.user_id, request.config.dict())
        background_tasks.add_task(build_project_task, project_id, request.config.dict())

        return {
            "success": True,
            "project_id": project_id,
            "status": "analyzing",
            "message": "–ü—Ä–æ–µ–∫—Ç —Å–æ–∑–¥–∞–Ω, –Ω–∞—á–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/projects/{project_id}")
async def get_project(project_id: str, user_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–µ–∫—Ç"""
    project = await db.get_project(project_id, user_id)
    if not project:
        raise HTTPException(status_code=404, detail="–ü—Ä–æ–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
    return project

@app.get("/projects")
async def list_projects(user_id: str):
    """–°–ø–∏—Å–æ–∫ –ø—Ä–æ–µ–∫—Ç–æ–≤"""
    return {"projects": await db.list_projects(user_id)}

async def build_project_task(project_id: str, config: dict):
    """–§–æ–Ω–æ–≤–∞—è —Å–±–æ—Ä–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞"""
    try:
        await db.update_project(project_id, {"status": "generating"})

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
        result = await project_builder.analyze_and_build(config)

        await db.update_project(project_id, {
            "status": "building",
            "files": result["files"],
            "architecture": result["architecture"],
            "tech_stack": result["tech_stack"]
        })

        # –î–µ–ø–ª–æ–π –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if config.get("auto_deploy"):
            await db.update_project(project_id, {"status": "deploying"})
            deploy_result = await deploy_engine.deploy(project_id, config["name"], result["files"])

            await db.update_project(project_id, {
                "status": "live" if deploy_result["success"] else "error",
                "deploy_url": deploy_result.get("deploy_url"),
                "github_url": deploy_result.get("github_url")
            })
        else:
            await db.update_project(project_id, {"status": "draft"})

    except Exception as e:
        await db.update_project(project_id, {"status": "error", "logs": str(e)})

# ============ STATUS ============

@app.get("/")
async def root():
    """–°—Ç–∞—Ç—É—Å –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã"""
    providers = ai_manager.get_available_providers()
    media_services = await media_processor.check_services()

    return {
        "status": "AI Developer Platform v4.0 —Ä–∞–±–æ—Ç–∞–µ—Ç",
        "version": "4.0.0",
        "modules": {
            "ai": {"providers": len([p for p in providers if p["available"]]), "status": "active"},
            "media": {"services": sum(media_services.values()), "status": "active"},
            "agents": {"count": len(agent_system.agents), "status": "active"},
            "rag": {"status": "active"},
            "nlp": {"status": "active"}
        },
        "features": [
            "multi-ai-providers", "local-ollama", "image-generation", 
            "video-generation", "tts-stt", "ai-agents", "rag-system",
            "nlp-database", "auto-deployment"
        ],
        "docs": "/docs"
    }

@app.get("/health")
async def health():
    """Health check"""
    return {"status": "ok", "version": "4.0.0"}

if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)
